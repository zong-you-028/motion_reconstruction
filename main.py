#!/usr/bin/env python3
"""
Learnable Projection POS - ä¸»ç¨‹å¼
One-Click Execution for Learnable Projection Matrix POS

é€™å€‹ç‰ˆæœ¬å°ˆé–€ç”¨æ–¼è¨“ç·´å’Œä½¿ç”¨å¯å­¸ç¿’æŠ•å½±çŸ©é™£çš„ POS æ¼”ç®—æ³•
"""

import os
import sys
import argparse
from pathlib import Path

def print_banner():
    """é¡¯ç¤ºæ­¡è¿ç•«é¢"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘      Learnable Projection Matrix POS (LP-POS)            â•‘
    â•‘         å¯è¨“ç·´æŠ•å½±çŸ©é™£ POS - ä¸€éµåŸ·è¡Œ                      â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    è¨“ç·´æ•´å€‹ 2Ã—3 æŠ•å½±çŸ©é™£ P(t)ï¼Œè€Œä¸åªæ˜¯ alpha åƒæ•¸
    """
    print(banner)

def check_dependencies():
    """æª¢æŸ¥å¿…è¦çš„ä¾è³´å¥—ä»¶"""
    required_packages = {
        'torch': 'PyTorch',
        'numpy': 'NumPy',
        'scipy': 'SciPy',
        'pandas': 'Pandas',
        'cv2': 'OpenCV (opencv-python)',
        'mediapipe': 'MediaPipe',
        'matplotlib': 'Matplotlib'
    }
    
    missing_packages = []
    
    print("æ­£åœ¨æª¢æŸ¥ä¾è³´å¥—ä»¶...")
    for package, name in required_packages.items():
        try:
            __import__(package)
            print(f"  âœ“ {name}")
        except ImportError:
            print(f"  âœ— {name} - æœªå®‰è£")
            missing_packages.append(name)
    
    if missing_packages:
        print("\nâš ï¸  ç¼ºå°‘ä»¥ä¸‹å¥—ä»¶ï¼Œè«‹å…ˆå®‰è£ï¼š")
        print(f"pip install {' '.join([p.split()[0].lower().replace('opencv', 'opencv-python') for p in missing_packages])}")
        return False
    
    print("\nâœ“ æ‰€æœ‰ä¾è³´å¥—ä»¶å·²å®‰è£\n")
    return True

def show_menu():
    """é¡¯ç¤ºä¸»é¸å–®"""
    menu = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è«‹é¸æ“‡è¦åŸ·è¡Œçš„åŠŸèƒ½ï¼š                                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  1. å¿«é€Ÿæ¸¬è©¦ (ä½¿ç”¨åˆæˆæ•¸æ“šè¨“ç·´)                           â”‚
    â”‚  2. è¨“ç·´æ¨¡å‹ (ä½¿ç”¨å¯¦éš›æ•¸æ“š)                               â”‚
    â”‚  3. è©•ä¼°æ¨¡å‹                                             â”‚
    â”‚  4. æå– ROI (å¾å½±ç‰‡å¹€)                                  â”‚
    â”‚  5. ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹æ¨è«–                                  â”‚
    â”‚  6. æ¯”è¼ƒä¸‰ç¨®æ¨¡å‹æ¶æ§‹                                      â”‚
    â”‚  0. é€€å‡º                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print(menu)

def quick_test():
    """é¸é … 1: å¿«é€Ÿæ¸¬è©¦"""
    print("\n" + "="*60)
    print("é¸é … 1: å¿«é€Ÿæ¸¬è©¦ (ä½¿ç”¨åˆæˆæ•¸æ“š)")
    print("="*60)
    
    print("\né€™å°‡ä½¿ç”¨åˆæˆæ•¸æ“šå¿«é€Ÿè¨“ç·´æ¨¡å‹")
    print("é è¨ˆæ™‚é–“ï¼š5-10 åˆ†é˜\n")
    
    confirm = input("ç¢ºèªé–‹å§‹ï¼Ÿ(y/n) [y]: ").strip().lower()
    if confirm and confirm != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    try:
        print("\næ­£åœ¨ç”Ÿæˆæ¸¬è©¦æ•¸æ“š...")
        from demo_usage import generate_synthetic_rppg_data
        import numpy as np
        
        # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
        rgb_traces = []
        ppg_signals = []
        
        for i in range(20):
            print(f"  ç”Ÿæˆå—è©¦è€… {i+1}/20...", end='\r')
            r, g, b, ppg, _ = generate_synthetic_rppg_data(
                duration=30, fs=84, 
                hr=np.random.uniform(60, 100),
                motion_strength=np.random.uniform(0.2, 0.6)
            )
            rgb_traces.append((r, g, b))
            ppg_signals.append(ppg)
        
        print("\nâœ“ æ•¸æ“šç”Ÿæˆå®Œæˆï¼")
        
        # è¨“ç·´
        print("\né–‹å§‹è¨“ç·´...")
        from train_projection_pos import train_projection_model, RPPGDatasetForProjection
        from learnable_projection_pos import ConstrainedProjectionPredictor
        from torch.utils.data import DataLoader
        import torch
        
        # åˆ†å‰²æ•¸æ“š
        split_idx = int(0.8 * len(rgb_traces))
        train_rgb = rgb_traces[:split_idx]
        train_ppg = ppg_signals[:split_idx]
        val_rgb = rgb_traces[split_idx:]
        val_ppg = ppg_signals[split_idx:]
        
        # å‰µå»ºæ•¸æ“šé›†
        train_dataset = RPPGDatasetForProjection(
            train_rgb, train_ppg, window_length=128, stride=32, mode='feature'
        )
        val_dataset = RPPGDatasetForProjection(
            val_rgb, val_ppg, window_length=128, stride=64, mode='feature'
        )
        
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
        
        # å‰µå»ºæ¨¡å‹
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"\nä½¿ç”¨è¨­å‚™: {device}")
        
        model = ConstrainedProjectionPredictor(
            input_dim=10, hidden_dim=64, use_residual=True
        )
        print(f"æ¨¡å‹åƒæ•¸é‡: {sum(p.numel() for p in model.parameters())}")
        
        # è¨“ç·´
        trained_model, train_losses, val_losses = train_projection_model(
            model, train_loader, val_loader,
            num_epochs=30,
            learning_rate=0.001,
            device=device,
            save_dir='./projection_models',
            model_type='feature'
        )
        
        print("\n" + "="*60)
        print("âœ“ è¨“ç·´å®Œæˆï¼")
        print("="*60)
        print(f"\nçµæœä¿å­˜åœ¨: ./projection_models/")
        print(f"  - best_projection_model.pth")
        print(f"  - projection_training_curves.png")
        print(f"\næœ€ä½³é©—è­‰æå¤±: {min(val_losses):.4f}")
        
    except Exception as e:
        print(f"\nâœ— éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()

def train_with_real_data():
    """é¸é … 2: ä½¿ç”¨å¯¦éš›æ•¸æ“šè¨“ç·´"""
    print("\n" + "="*60)
    print("é¸é … 2: è¨“ç·´æ¨¡å‹ (ä½¿ç”¨å¯¦éš›æ•¸æ“š)")
    print("="*60)
    
    print("\næ­¤åŠŸèƒ½éœ€è¦å·²ç¶“æå–å¥½çš„ RGB traces å’Œ PPG æ•¸æ“š")
    print("æ•¸æ“šæ ¼å¼è¦æ±‚ï¼š")
    print("  - RGB traces: CSV æª”æ¡ˆ (frame, R_avg, G_avg, B_avg, success)")
    print("  - PPG: .mat æˆ– .csv æª”æ¡ˆ")
    
    data_dir = input("\nè«‹è¼¸å…¥æ•¸æ“šç›®éŒ„è·¯å¾‘: ").strip()
    if not data_dir or not os.path.exists(data_dir):
        print("\nâœ— éŒ¯èª¤ï¼šç›®éŒ„ä¸å­˜åœ¨")
        return
    
    output_dir = input("è«‹è¼¸å…¥è¼¸å‡ºç›®éŒ„è·¯å¾‘ [é è¨­: ./projection_models]: ").strip()
    if not output_dir:
        output_dir = './projection_models'
    
    print("\né¸æ“‡æ¨¡å‹é¡å‹ï¼š")
    print("  1. ConstrainedProjectionPredictor (æ¨è–¦ï¼ŒResidual æ¨¡å¼)")
    print("  2. ProjectionMatrixPredictor (åŸºç¤)")
    print("  3. TemporalProjectionPredictor (æ™‚åºï¼ŒLSTM)")
    
    model_choice = input("è«‹é¸æ“‡ [é è¨­: 1]: ").strip()
    if not model_choice:
        model_choice = '1'
    
    epochs = input("è¨“ç·´è¼ªæ•¸ [é è¨­: 50]: ").strip()
    num_epochs = int(epochs) if epochs else 50
    
    print("\næº–å‚™è¨“ç·´...")
    print(f"  æ•¸æ“šç›®éŒ„: {data_dir}")
    print(f"  è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"  è¨“ç·´è¼ªæ•¸: {num_epochs}")
    
    confirm = input("\nç¢ºèªåŸ·è¡Œï¼Ÿ(y/n) [y]: ").strip().lower()
    if confirm and confirm != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    try:
        from data_loader import DataLoader
        from train_projection_pos import train_projection_model, RPPGDatasetForProjection
        from learnable_projection_pos import (
            ProjectionMatrixPredictor,
            ConstrainedProjectionPredictor,
            TemporalProjectionPredictor
        )
        from torch.utils.data import DataLoader as TorchDataLoader
        import torch
        
        # è¼‰å…¥æ•¸æ“š
        print("\næ­£åœ¨è¼‰å…¥æ•¸æ“š...")
        
        # æƒææ•¸æ“šç›®éŒ„
        data_path = Path(data_dir)
        rgb_traces = []
        ppg_signals = []
        
        # æ”¶é›†æ‰€æœ‰å—è©¦è€…çš„æª”æ¡ˆè·¯å¾‘
        subject_list = []
        
        # æª¢æŸ¥å­ç›®éŒ„
        for subject_dir in data_path.iterdir():
            if subject_dir.is_dir():
                csv_files = list(subject_dir.glob('*rgb_traces.csv'))
                ppg_files = list(subject_dir.glob('ppg.*')) + list(subject_dir.glob('PPG*.csv'))
                
                if csv_files and ppg_files:
                    subject_list.append({
                        'subject_id': subject_dir.name,
                        'rgb_csv_path': str(csv_files[0]),
                        'ppg_path': str(ppg_files[0]),
                        'rgb_start_frame': 0
                    })
        
        # æª¢æŸ¥æ ¹ç›®éŒ„ï¼ˆå–®å€‹å—è©¦è€…æƒ…æ³ï¼‰
        csv_files_root = list(data_path.glob('*rgb_traces.csv'))
        ppg_files_root = list(data_path.glob('ppg.*')) + list(data_path.glob('PPG*.csv'))
        
        if csv_files_root and ppg_files_root:
            subject_list.append({
                'subject_id': 'single_subject',
                'rgb_csv_path': str(csv_files_root[0]),
                'ppg_path': str(ppg_files_root[0]),
                'rgb_start_frame': 0
            })
        
        if len(subject_list) == 0:
            print("\nâœ— éŒ¯èª¤ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•¸æ“š")
            print("\nè«‹ç¢ºèªæ•¸æ“šçµæ§‹ï¼š")
            print("  æ–¹å¼ 1ï¼ˆå¤šå—è©¦è€…ï¼‰ï¼š")
            print("    data_dir/")
            print("      subject1/")
            print("        subject1_rgb_traces.csv")
            print("        ppg.csv")
            print("      subject2/")
            print("        subject2_rgb_traces.csv")
            print("        ppg.csv")
            print("\n  æ–¹å¼ 2ï¼ˆå–®å—è©¦è€…ï¼‰ï¼š")
            print("    data_dir/")
            print("      xxx_rgb_traces.csv")
            print("      ppg.csv")
            return
        
        # ä½¿ç”¨ DataLoader è¼‰å…¥æ‰€æœ‰æ•¸æ“š
        loader = DataLoader(data_dir=str(data_path), fs=84)
        all_data = loader.load_multiple_subjects(subject_list)
        
        if len(all_data) == 0:
            print("\nâœ— éŒ¯èª¤ï¼šæœªèƒ½è¼‰å…¥ä»»ä½•æ•¸æ“š")
            return
        
        # è½‰æ›ç‚ºè¨“ç·´æ ¼å¼
        for data in all_data:
            r = data['r']
            g = data['g']
            b = data['b']
            ppg = data['ppg']
            
            rgb_traces.append((r, g, b))
            ppg_signals.append(ppg)
        
        if len(rgb_traces) == 0:
            print("\nâœ— éŒ¯èª¤ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•¸æ“š")
            return
        
        print(f"\nâœ“ è¼‰å…¥ {len(rgb_traces)} å€‹å—è©¦è€…çš„æ•¸æ“š")
        
        # åˆ†å‰²æ•¸æ“š
        split_idx = int(0.8 * len(rgb_traces))
        train_rgb = rgb_traces[:split_idx]
        train_ppg = ppg_signals[:split_idx]
        val_rgb = rgb_traces[split_idx:]
        val_ppg = ppg_signals[split_idx:]
        
        print(f"  è¨“ç·´é›†: {len(train_rgb)} å€‹å—è©¦è€…")
        print(f"  é©—è­‰é›†: {len(val_rgb)} å€‹å—è©¦è€…")
        
        # å‰µå»ºæ¨¡å‹
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"\nä½¿ç”¨è¨­å‚™: {device}")
        
        if model_choice == '1':
            model = ConstrainedProjectionPredictor(input_dim=10, hidden_dim=64, use_residual=True)
            model_type = 'feature'
            dataset_mode = 'feature'
            print("ä½¿ç”¨æ¨¡å‹: ConstrainedProjectionPredictor (Residual)")
        elif model_choice == '2':
            model = ProjectionMatrixPredictor(input_dim=10, hidden_dim=64)
            model_type = 'feature'
            dataset_mode = 'feature'
            print("ä½¿ç”¨æ¨¡å‹: ProjectionMatrixPredictor")
        else:
            model = TemporalProjectionPredictor(window_size=128, hidden_dim=64)
            model_type = 'sequence'
            dataset_mode = 'sequence'
            print("ä½¿ç”¨æ¨¡å‹: TemporalProjectionPredictor (LSTM)")
        
        print(f"æ¨¡å‹åƒæ•¸é‡: {sum(p.numel() for p in model.parameters())}")
        
        # å‰µå»ºæ•¸æ“šé›†
        print("\nå‰µå»ºæ•¸æ“šé›†...")
        train_dataset = RPPGDatasetForProjection(
            train_rgb, train_ppg, window_length=128, stride=32, mode=dataset_mode
        )
        val_dataset = RPPGDatasetForProjection(
            val_rgb, val_ppg, window_length=128, stride=64, mode=dataset_mode
        )
        
        train_loader = TorchDataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = TorchDataLoader(val_dataset, batch_size=16, shuffle=False)
        
        print(f"  è¨“ç·´æ¨£æœ¬: {len(train_dataset)}")
        print(f"  é©—è­‰æ¨£æœ¬: {len(val_dataset)}")
        
        # è¨“ç·´
        print("\né–‹å§‹è¨“ç·´...")
        trained_model, train_losses, val_losses = train_projection_model(
            model, train_loader, val_loader,
            num_epochs=num_epochs,
            learning_rate=0.001,
            device=device,
            save_dir=output_dir,
            model_type=model_type
        )
        
        print("\n" + "="*60)
        print("âœ“ è¨“ç·´å®Œæˆï¼")
        print("="*60)
        print(f"\nçµæœä¿å­˜åœ¨: {output_dir}/")
        print(f"æœ€ä½³é©—è­‰æå¤±: {min(val_losses):.4f}")
        
    except Exception as e:
        print(f"\nâœ— éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()

def evaluate_model():
    """é¸é … 3: è©•ä¼°æ¨¡å‹"""
    print("\n" + "="*60)
    print("é¸é … 3: è©•ä¼°æ¨¡å‹")
    print("="*60)
    
    model_path = input("\nè«‹è¼¸å…¥æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth): ").strip()
    if not model_path or not os.path.exists(model_path):
        print("\nâœ— éŒ¯èª¤ï¼šæ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
        return
    
    data_dir = input("è«‹è¼¸å…¥æ¸¬è©¦æ•¸æ“šç›®éŒ„: ").strip()
    if not data_dir or not os.path.exists(data_dir):
        print("\nâœ— éŒ¯èª¤ï¼šç›®éŒ„ä¸å­˜åœ¨")
        return
    
    print("\nåŠŸèƒ½é–‹ç™¼ä¸­...")
    print("ç›®å‰è«‹ä½¿ç”¨ evaluate_adaptive_pos.py é€²è¡Œè©•ä¼°")

def extract_roi():
    """é¸é … 4: æå– ROI"""
    print("\n" + "="*60)
    print("é¸é … 4: æå– ROI")
    print("="*60)
    
    frames_folder = input("\nè«‹è¼¸å…¥å½±ç‰‡å¹€æ‰€åœ¨ç›®éŒ„ (å¯ä»¥æ˜¯ NAS è·¯å¾‘): ").strip()
    if not frames_folder or not os.path.exists(frames_folder):
        print("\nâœ— éŒ¯èª¤ï¼šç›®éŒ„ä¸å­˜åœ¨")
        return
    
    subject_id = input("è«‹è¼¸å…¥å—è©¦è€… ID: ").strip()
    if not subject_id:
        print("\nâœ— éŒ¯èª¤ï¼šéœ€è¦æä¾›å—è©¦è€… ID")
        return
    
    output_dir = input("è«‹è¼¸å…¥è¼¸å‡ºç›®éŒ„ (æœ¬åœ°è·¯å¾‘ï¼Œé è¨­: ./FaceMesh_Output): ").strip()
    if not output_dir:
        output_dir = os.path.join(os.getcwd(), 'FaceMesh_Output')
    
    print(f"\nğŸ“ è®€å–ä¾†æº: {frames_folder}")
    print(f"ğŸ’¾ è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    try:
        from facemesh_roi_cheeks_only import process_roi_extraction
        import pandas as pd
        
        print(f"\næ­£åœ¨è™•ç† {subject_id}...")
        results = process_roi_extraction(frames_folder, subject_id, output_dir)
        
        # ä¿å­˜ CSV
        csv_path = os.path.join(output_dir, f'{subject_id}_rgb_traces.csv')
        df = pd.DataFrame(results)
        df.to_csv(csv_path, index=False)
        
        print(f"\nâœ“ ROI æå–å®Œæˆï¼")
        print(f"çµæœå·²è¼¸å‡ºï¼ˆå…± {len(results)} å¹€ï¼‰")
        print(f"CSV æª”æ¡ˆ: {csv_path}")
        
    except Exception as e:
        print(f"\nâœ— éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()

def inference_with_model():
    """é¸é … 5: ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹æ¨è«–"""
    print("\n" + "="*60)
    print("é¸é … 5: æ¨¡å‹æ¨è«–")
    print("="*60)
    
    model_path = input("\nè«‹è¼¸å…¥æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth): ").strip()
    if not model_path or not os.path.exists(model_path):
        print("\nâœ— éŒ¯èª¤ï¼šæ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
        return
    
    csv_path = input("è«‹è¼¸å…¥ RGB traces CSV æª”æ¡ˆè·¯å¾‘: ").strip()
    if not csv_path or not os.path.exists(csv_path):
        print("\nâœ— éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸å­˜åœ¨")
        return
    
    try:
        import torch
        import pandas as pd
        import numpy as np
        from learnable_projection_pos import (
            ConstrainedProjectionPredictor,
            LearnableProjectionPOS
        )
        from scipy.stats import pearsonr
        
        # è¼‰å…¥æ¨¡å‹
        print("\næ­£åœ¨è¼‰å…¥æ¨¡å‹...")
        checkpoint = torch.load(model_path, map_location='cpu')
        
        model = ConstrainedProjectionPredictor(input_dim=10, hidden_dim=64, use_residual=True)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        print("âœ“ æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
        # è¼‰å…¥æ•¸æ“š
        print("\næ­£åœ¨è¼‰å…¥ RGB æ•¸æ“š...")
        df = pd.read_csv(csv_path)
        df = df[df['success'] == 1]
        
        r_buf = df['R_avg'].values
        g_buf = df['G_avg'].values
        b_buf = df['B_avg'].values
        print(f"âœ“ æ•¸æ“šè¼‰å…¥å®Œæˆï¼ˆ{len(r_buf)} å¹€ï¼‰")
        
        # è™•ç†
        print("\næ­£åœ¨è™•ç†...")
        pos = LearnableProjectionPOS(window_length=128, fs=84)
        
        # æ¨™æº– POS
        rppg_standard = pos.process_standard(r_buf, g_buf, b_buf)
        
        # å¯å­¸ç¿’æŠ•å½±çŸ©é™£ POS
        rppg_learnable, P_history = pos.process_learnable(
            r_buf, g_buf, b_buf, model, use_features=True
        )
        
        # è¨ˆç®—å¿ƒç‡
        from learnable_projection_pos import calculate_hr_from_rppg
        hr_std = calculate_hr_from_rppg(rppg_standard[128:], fs=84)
        hr_learn = calculate_hr_from_rppg(rppg_learnable[128:], fs=84)
        
        # é¡¯ç¤ºçµæœ
        print("\n" + "="*60)
        print("è™•ç†å®Œæˆï¼")
        print("="*60)
        
        print(f"\næ¨™æº– POS:")
        print(f"  å¿ƒç‡: {hr_std:.1f} bpm")
        
        print(f"\nå¯å­¸ç¿’æŠ•å½±çŸ©é™£ POS:")
        print(f"  å¿ƒç‡: {hr_learn:.1f} bpm")
        
        print(f"\næŠ•å½±çŸ©é™£è®ŠåŒ–:")
        print(f"  æ¨™æº– POS: [[0, 1, -1], [-2, 1, 1]]")
        print(f"  å­¸ç¿’åˆ°çš„ P(t=0):\n    {P_history[0]}")
        P_standard = np.array([[0, 1, -1], [-2, 1, 1]])
        deviation = np.mean(np.abs(P_history - P_standard))
        print(f"  å¹³å‡åé›¢æ¨™æº– POS: {deviation:.3f}")
        
        # å¯è¦–åŒ–
        try:
            import matplotlib.pyplot as plt
            
            fig, axes = plt.subplots(2, 3, figsize=(15, 8))
            fig.suptitle('æŠ•å½±çŸ©é™£éš¨æ™‚é–“è®ŠåŒ–', fontsize=16)
            
            for i in range(2):
                for j in range(3):
                    ax = axes[i, j]
                    ax.plot(P_history[:, i, j], label='Learned', linewidth=2)
                    ax.axhline(P_standard[i, j], color='r', linestyle='--', 
                             label='Standard', linewidth=2)
                    ax.set_title(f'P[{i},{j}]')
                    ax.set_xlabel('Time (frames)')
                    ax.set_ylabel('Value')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            output_path = 'projection_matrix_evolution.png'
            plt.savefig(output_path, dpi=150)
            print(f"\nå¯è¦–åŒ–åœ–å·²ä¿å­˜: {output_path}")
        except:
            pass
        
    except Exception as e:
        print(f"\nâœ— éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()

def compare_models():
    """é¸é … 6: æ¯”è¼ƒä¸‰ç¨®æ¨¡å‹æ¶æ§‹"""
    print("\n" + "="*60)
    print("é¸é … 6: æ¯”è¼ƒä¸‰ç¨®æ¨¡å‹æ¶æ§‹")
    print("="*60)
    
    print("\nå°‡è¨“ç·´å’Œæ¯”è¼ƒä¸‰ç¨®æ¨¡å‹ï¼š")
    print("  1. ProjectionMatrixPredictor (åŸºç¤)")
    print("  2. ConstrainedProjectionPredictor (Residual)")
    print("  3. TemporalProjectionPredictor (LSTM)")
    
    print("\né è¨ˆæ™‚é–“ï¼š15-30 åˆ†é˜")
    
    confirm = input("\nç¢ºèªé–‹å§‹ï¼Ÿ(y/n) [y]: ").strip().lower()
    if confirm and confirm != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    print("\nåŠŸèƒ½é–‹ç™¼ä¸­...")
    print("ç›®å‰è«‹åˆ†åˆ¥é‹è¡Œé¸é … 1 ä¸‰æ¬¡ï¼Œæ¯æ¬¡é¸æ“‡ä¸åŒçš„æ¨¡å‹")

def main():
    """ä¸»ç¨‹å¼"""
    # é¡¯ç¤ºæ­¡è¿ç•«é¢
    print_banner()
    
    # æª¢æŸ¥ä¾è³´
    if not check_dependencies():
        sys.exit(1)
    
    # ä¸»å¾ªç’°
    while True:
        show_menu()
        choice = input("è«‹é¸æ“‡ (0-6): ").strip()
        
        if choice == '0':
            print("\nå†è¦‹ï¼ğŸ‘‹")
            break
        elif choice == '1':
            quick_test()
        elif choice == '2':
            train_with_real_data()
        elif choice == '3':
            evaluate_model()
        elif choice == '4':
            extract_roi()
        elif choice == '5':
            inference_with_model()
        elif choice == '6':
            compare_models()
        else:
            print("\nâœ— ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
        
        # ç­‰å¾…ç”¨æˆ¶
        input("\næŒ‰ Enter ç¹¼çºŒ...")
        print("\n" * 2)

if __name__ == "__main__":
    # æ”¯æ´å‘½ä»¤åˆ—åƒæ•¸ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    parser = argparse.ArgumentParser(description='Learnable Projection POS - ä¸€éµåŸ·è¡Œ')
    parser.add_argument('--quick-test', action='store_true', help='ç›´æ¥é‹è¡Œå¿«é€Ÿæ¸¬è©¦')
    parser.add_argument('--train', type=str, help='è¨“ç·´æ¨¡å‹ï¼ˆæŒ‡å®šæ•¸æ“šç›®éŒ„ï¼‰')
    parser.add_argument('--inference', nargs=2, metavar=('MODEL', 'CSV'), 
                       help='æ¨è«–æ¨¡å¼ï¼ˆæ¨¡å‹è·¯å¾‘ CSVè·¯å¾‘ï¼‰')
    
    args = parser.parse_args()
    
    if args.quick_test:
        # å¿«é€Ÿæ¨¡å¼
        print_banner()
        quick_test()
    elif args.train:
        # è¨“ç·´æ¨¡å¼
        print_banner()
        # TODO: å¯¦ç¾å¿«é€Ÿè¨“ç·´
        print("å‘½ä»¤åˆ—å¿«é€Ÿæ¨¡å¼é–‹ç™¼ä¸­...")
    elif args.inference:
        # æ¨è«–æ¨¡å¼
        print_banner()
        # TODO: å¯¦ç¾å¿«é€Ÿæ¨è«–
        print("å‘½ä»¤åˆ—æ¨è«–æ¨¡å¼é–‹ç™¼ä¸­...")
    else:
        # äº’å‹•å¼é¸å–®æ¨¡å¼
        main()